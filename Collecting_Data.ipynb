{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Collecting Data\n",
    "------------------------------\n",
    "\n",
    "**Overview**\n",
    " - Data are scraped from one of the most popular polish online marketplace for car shoppers and sellers: otomoto.pl\n",
    " - Specific car model is chosen: Opel (GM) Astra.\n",
    " - I scrapp from offers such information as: price, year of production, mileage, etc.\n",
    " - The scraped information is put to pandas DataFrame\n",
    " - The DataFrame are saved to csv file.\n",
    "-------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Scraping links to offers\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Getting a page source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get as rqst_get\n",
    "from contextlib import closing\n",
    "\n",
    "def get_content_from_url(url):\n",
    "    with closing(rqst_get(url, stream=True)) as cnt:\n",
    "        return cnt.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Extracting links from BeautifulSoup objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_links(bfs):\n",
    "    links = []\n",
    "    for link in bfs.find_all('a', class_='offer-title__link'):\n",
    "        links.append(str(link.get('href')))\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Exploring website for links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_website(core_url, suffix='?page=', n_pages=3):\n",
    "    bfs = BeautifulSoup(get_content_from_url(core_url), 'html.parser')\n",
    "    links = extract_links(bfs)\n",
    "    for i in range(1,n_pages+1):\n",
    "        new_url = core_url+suffix+str(i)\n",
    "        bfs = BeautifulSoup(get_content_from_url(new_url), 'html.parser')\n",
    "        links += extract_links(bfs)\n",
    "    links = list(set(links)) # delete duplicates\n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Getting links to offer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_to_offers = 'https://www.otomoto.pl/osobowe/opel/astra/'\n",
    "links = explore_website(url_to_offers, n_pages=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Scraping data from offers\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Finding price in the page source. (In case of problem, put 'Null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_price(bfs):\n",
    "    price = ['Cena']\n",
    "    try:\n",
    "        price.append( float(list(bfs.find(class_='offer-price__number').stripped_strings)[0].replace(' ','')))\n",
    "    except:\n",
    "        price.append('Null')\n",
    "    return price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Finding items in the page source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_items(bfs):\n",
    "    items = []\n",
    "    try:\n",
    "        items_class = bfs.find_all(class_='offer-params__item')\n",
    "        for item_class in items_class:\n",
    "            items.append(list(item_class.stripped_strings))\n",
    "    except:\n",
    "        items = 'Null'\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Finding features in the page source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(bfs):\n",
    "    features = []\n",
    "    try:\n",
    "        features_class = bfs.find_all(class_='offer-features__item')\n",
    "        for feature_class in features_class:\n",
    "            features.append(list(feature_class.stripped_strings))\n",
    "    except:\n",
    "        features.append('Null')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Adding row to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros, repeat, array\n",
    "def add_to_dataframe(df, price, items, features):\n",
    "    current_index = 0\n",
    "    if len(df.index) == 0:\n",
    "        df.loc[0] = zeros(df.columns.size)\n",
    "    else:\n",
    "        df.loc[df.index[-1]+1] = zeros(df.columns.size)\n",
    "        current_index = df.index[-1]\n",
    "    df.loc[current_index, 'Cena'] = price[1]\n",
    "    if items != 'Null':\n",
    "        for item, value in items:\n",
    "            if item not in df.columns:\n",
    "                df[item] = repeat(0, len(df))\n",
    "            df.loc[current_index, item] = value\n",
    "    if features != 'Null':\n",
    "        features = array(features).flatten()\n",
    "        for feature in features:\n",
    "            if feature not in df.columns:\n",
    "                df[feature] = repeat(0, len(df))\n",
    "            df.loc[current_index, feature] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Gathering data to DataFrame for every link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({'Cena': []})\n",
    "for offer_link in links:\n",
    "    offer_bfs = BeautifulSoup(get_content_from_url(offer_link), 'html.parser')\n",
    "    price = find_price(offer_bfs)\n",
    "    items = find_items(offer_bfs)\n",
    "    features = find_features(offer_bfs)\n",
    "    add_to_dataframe(data, price, items, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Saving DataFrame to file\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('car_offers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
